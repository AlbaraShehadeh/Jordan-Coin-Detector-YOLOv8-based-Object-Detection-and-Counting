{"cells":[{"cell_type":"markdown","metadata":{"id":"z3A2p9cHtxb7"},"source":["## Install & Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"tbJlsLMvspIU"},"outputs":[],"source":["!pip install -q ultralytics"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ZvAgJL04owHu"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from tqdm import tqdm\n","from ultralytics import YOLO\n","from collections import defaultdict"]},{"cell_type":"markdown","metadata":{"id":"EKaCiFW0VyNf"},"source":["## Image Inference"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"13UAIoDZjaAGMXRlSUzB9CjBYFJlcydWX"},"executionInfo":{"elapsed":17429,"status":"ok","timestamp":1708518598640,"user":{"displayName":"Albara Shehadeh","userId":"03982301414393354932"},"user_tz":-180},"id":"wlnp7szqjl-u","outputId":"6360be4b-df6d-41fd-e0cc-e30ec539ca12"},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","0: 640x640 2 1-4-dinars, 1 10-Piastres, 2 10-dinars, 1 20-dinar, 2 5-Piastress, 24.0ms\n","Speed: 2.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 480x640 1 1-2-dinar, 2 1-dinars, 3 10-Piastress, 1 10-dinar, 1 5-Piastres, 2 5-dinars, 19.0ms\n","Speed: 1.0ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 640x640 1 1-2-dinar, 1 1-4-dinar, 2 1-dinars, 2 50-dinars, 24.0ms\n","Speed: 2.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 1 20-dinar, 22.0ms\n","Speed: 2.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"]}],"source":["import cv2\n","import numpy as np\n","import os\n","from glob import glob\n","from ultralytics import YOLO\n","from ultralytics.utils.plotting import Annotator, colors\n","from collections import defaultdict\n","\n","model = YOLO(\"model.pt\")\n","names = model.model.names\n","\n","input_images_folder = \"images/\"\n","output_results_folder = \"results/\"\n","image_files = glob(os.path.join(input_images_folder, \"*.jpg\"))\n","\n","# Ensure the output folder exists\n","os.makedirs(output_results_folder, exist_ok=True)\n","\n","# Initialize variables\n","confidence_threshold = 0.7\n","coin_value_mapping = {0: 0.50, 1: 0.25, 2: 1, 3: 0.10, 4: 10, 5: 20, 6: 0.05, 7: 5, 8: 50}\n","\n","# Process each image in the folder\n","for image_file in image_files:\n","\n","    coin_counts = defaultdict(int)\n","\n","    image = cv2.imread(image_file)\n","    results = model(image)\n","    boxes = results[0].boxes.xyxy.cpu()\n","\n","    # Annotator Init\n","    annotator = Annotator(image, line_width=2)\n","\n","    # Process detected objects\n","    for box, cls, conf in zip(boxes, results[0].boxes.cls.cpu().tolist(), results[0].boxes.conf.float().cpu().tolist()):\n","        # Filter out predictions below the confidence threshold\n","        if conf >= confidence_threshold:\n","            annotator.box_label(box, color=colors(int(cls), True), label=f\"{names[int(cls)]} {conf:.2f}\")\n","            coin_counts[int(cls)] += 1\n","\n","    # Calculate total value and update counter\n","    counter = len(boxes)\n","    total_value = sum(coin_value_mapping[coin_type] * count for coin_type, count in coin_counts.items())\n","\n","    font = cv2.FONT_HERSHEY_SIMPLEX\n","    font_size = 1\n","    font_thickness = 2\n","\n","    cv2.putText(image, f'Number of Objects: {counter}', (10, 50), font, font_size, (255, 0, 0), font_thickness, cv2.LINE_AA)\n","    cv2.putText(image, f'Total Value: {total_value:.2f} JD', (10, 20), font, font_size, (255, 0, 0), font_thickness, cv2.LINE_AA)\n","\n","    # Save the result image in the output folder\n","    result_image_path = os.path.join(output_results_folder, os.path.basename(image_file))\n","    cv2.imwrite(result_image_path, image)\n"]},{"cell_type":"markdown","metadata":{"id":"ba6s8Xi1pQue"},"source":["## Video Inference"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3MG1hFd8spMp","outputId":"c5eaf35b-7a8a-41ba-dcb2-a97e45dea098"},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","0: 640x384 1 1-2-dinar, 2 10-Piastress, 2 5-Piastress, 2 50-dinars, 136.0ms\n","Speed: 2.0ms preprocess, 136.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 2 10-Piastress, 2 5-Piastress, 2 50-dinars, 15.0ms\n","Speed: 2.0ms preprocess, 15.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 2 10-Piastress, 2 5-Piastress, 2 50-dinars, 14.0ms\n","Speed: 2.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 2 10-Piastress, 2 5-Piastress, 2 50-dinars, 15.0ms\n","Speed: 2.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 2 10-Piastress, 1 5-Piastres, 2 50-dinars, 14.0ms\n","Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 2 10-Piastress, 1 5-Piastres, 2 50-dinars, 15.0ms\n","Speed: 2.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 3 10-Piastress, 1 5-Piastres, 1 50-dinar, 15.0ms\n","Speed: 1.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 2 10-Piastress, 1 5-Piastres, 1 50-dinar, 15.0ms\n","Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 2 10-Piastress, 1 5-Piastres, 1 50-dinar, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 2 10-Piastress, 1 5-Piastres, 1 50-dinar, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 2 10-Piastress, 1 5-Piastres, 1 50-dinar, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 2 10-Piastress, 1 5-Piastres, 1 50-dinar, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 2 10-Piastress, 1 5-Piastres, 1 50-dinar, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 2 10-Piastress, 2 5-Piastress, 1 50-dinar, 12.0ms\n","Speed: 1.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 2 10-Piastress, 2 5-Piastress, 1 50-dinar, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 10-Piastres, 2 5-Piastress, 1 50-dinar, 13.0ms\n","Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 3 10-Piastress, 1 5-Piastres, 1 50-dinar, 12.0ms\n","Speed: 1.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 3 10-Piastress, 1 5-Piastres, 1 50-dinar, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 3 10-Piastress, 3 5-Piastress, 1 50-dinar, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 3 10-Piastress, 1 5-Piastres, 1 50-dinar, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 3 10-Piastress, 1 5-Piastres, 1 50-dinar, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 3 10-Piastress, 1 5-Piastres, 1 50-dinar, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 1 50-dinar, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 1 50-dinar, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 3 10-Piastress, 1 5-Piastres, 1 50-dinar, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 3 10-Piastress, 1 5-Piastres, 1 50-dinar, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 3 10-Piastress, 2 5-Piastress, 1 50-dinar, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 3 10-Piastress, 2 5-Piastress, 1 50-dinar, 13.0ms\n","Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 1 50-dinar, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 1 50-dinar, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 1 50-dinar, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 14.0ms\n","Speed: 1.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 2.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 13.0ms\n","Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 4 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 4 10-Piastress, 2 5-Piastress, 2 50-dinars, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 12.0ms\n","Speed: 1.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 4 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 12.0ms\n","Speed: 1.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 13.0ms\n","Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 13.0ms\n","Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 13.0ms\n","Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 13.0ms\n","Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 2.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 12.0ms\n","Speed: 1.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 12.0ms\n","Speed: 1.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 12.0ms\n","Speed: 1.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 2.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 2 10-Piastress, 2 5-Piastress, 2 50-dinars, 13.0ms\n","Speed: 2.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 12.0ms\n","Speed: 1.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 2 10-Piastress, 2 5-Piastress, 2 50-dinars, 13.0ms\n","Speed: 2.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 3 10-Piastress, 2 5-Piastress, 2 50-dinars, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 2 10-Piastress, 1 5-Piastres, 2 50-dinars, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 2 10-Piastress, 2 5-Piastress, 2 50-dinars, 13.0ms\n","Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 2 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 3.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 2 10-Piastress, 1 5-Piastres, 3 50-dinars, 13.0ms\n","Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 2 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-2-dinar, 1 1-dinar, 2 10-Piastress, 2 5-Piastress, 1 50-dinar, 12.0ms\n","Speed: 1.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 2 10-Piastress, 2 5-Piastress, 1 50-dinar, 13.0ms\n","Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 2 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 2 10-Piastress, 1 5-Piastres, 2 50-dinars, 12.0ms\n","Speed: 1.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 2 10-Piastress, 2 5-Piastress, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 2 10-Piastress, 2 5-Piastress, 2 50-dinars, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 12.0ms\n","Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 2 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 2 10-Piastress, 1 5-Piastres, 2 50-dinars, 13.0ms\n","Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 2 10-Piastress, 1 5-Piastres, 2 50-dinars, 12.0ms\n","Speed: 1.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 2 10-Piastress, 1 5-Piastres, 2 50-dinars, 20.0ms\n","Speed: 1.0ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 1 10-Piastres, 1 5-Piastres, 2 50-dinars, 21.0ms\n","Speed: 2.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 20.0ms\n","Speed: 2.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 2 10-Piastress, 1 5-Piastres, 3 50-dinars, 20.0ms\n","Speed: 1.0ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 21.0ms\n","Speed: 1.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 2 1-dinars, 3 10-Piastress, 2 50-dinars, 21.0ms\n","Speed: 2.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 2 1-dinars, 3 10-Piastress, 2 50-dinars, 26.0ms\n","Speed: 2.0ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 2 10-Piastress, 1 5-Piastres, 2 50-dinars, 30.0ms\n","Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 2 10-Piastress, 1 5-Piastres, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 2 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 2 10-Piastress, 2 50-dinars, 30.0ms\n","Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 2 10-Piastress, 1 5-Piastres, 2 50-dinars, 30.0ms\n","Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 2 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 2 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 2 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 2 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 2 10-Piastress, 1 5-Piastres, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 2 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 2 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 2 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 2 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 2 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 2 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 2 10-Piastress, 2 50-dinars, 28.0ms\n","Speed: 2.0ms preprocess, 28.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 2 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 2 10-Piastress, 2 50-dinars, 30.0ms\n","Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 2 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 2 10-Piastress, 2 50-dinars, 30.0ms\n","Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 2 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 2 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 2 10-Piastress, 2 50-dinars, 28.0ms\n","Speed: 2.0ms preprocess, 28.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 2 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 2 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 2 10-Piastress, 2 50-dinars, 28.0ms\n","Speed: 2.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 2 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 2 10-Piastress, 2 50-dinars, 28.0ms\n","Speed: 2.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 2 10-Piastress, 2 50-dinars, 28.0ms\n","Speed: 2.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 2 10-Piastress, 2 50-dinars, 28.0ms\n","Speed: 2.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 28.0ms\n","Speed: 2.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 30.0ms\n","Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 28.0ms\n","Speed: 2.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 28.0ms\n","Speed: 2.0ms preprocess, 28.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 28.0ms\n","Speed: 1.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 28.0ms\n","Speed: 1.0ms preprocess, 28.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 30.0ms\n","Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 30.0ms\n","Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 28.0ms\n","Speed: 2.0ms preprocess, 28.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 30.0ms\n","Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 30.0ms\n","Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 30.0ms\n","Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 30.0ms\n","Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 30.0ms\n","Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 30.0ms\n","Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 29.0ms\n","Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 2 50-dinars, 29.0ms\n","Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n","\n","0: 640x384 1 1-dinar, 3 10-Piastress, 1 5-Piastres, 2 50-dinars, 28.0ms\n","Speed: 1.0ms preprocess, 28.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n"]}],"source":["import cv2\n","from glob import glob\n","from ultralytics import YOLO\n","from ultralytics.utils.plotting import Annotator, colors\n","from collections import defaultdict\n","\n","model = YOLO(\"model.pt\")\n","names = model.model.names\n","\n","input_video_path = \"videos/1.mp4\"\n","output_video_path = \"results/1-result.mp4\"\n","cap = cv2.VideoCapture(input_video_path)\n","assert cap.isOpened(), \"Error reading video file\"\n","\n","# Initialize variables\n","font = cv2.FONT_HERSHEY_SIMPLEX\n","counter = 0\n","coin_counts = defaultdict(int)\n","confidence_threshold = 0.7\n","coin_value_mapping = {0: 0.50, 1: 0.25, 2: 1, 3: 0.10, 4: 10, 5: 20, 6: 0.05, 7: 5, 8: 50}\n","\n","# Get video properties\n","fps = cap.get(cv2.CAP_PROP_FPS)\n","width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","# Create VideoWriter object for output\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n","\n","while True:\n","    ret, frame = cap.read()\n","\n","    if not ret:\n","        break\n","\n","    results = model(frame)\n","    boxes = results[0].boxes.xyxy.cpu()\n","\n","    # Annotator Init\n","    annotator = Annotator(frame, line_width=2)\n","\n","    # Process detected objects\n","    for box, cls, conf in zip(boxes, results[0].boxes.cls.cpu().tolist(), results[0].boxes.conf.float().cpu().tolist()):\n","        # Filter out predictions below the confidence threshold\n","        if conf >= confidence_threshold:\n","            annotator.box_label(box, color=colors(int(cls), True), label=f\"{names[int(cls)]} {conf:.2f}\")\n","\n","            # Update coin counts\n","            coin_counts[int(cls)] += 1\n","\n","    # Calculate total value and update counter\n","    counter = len(boxes)  # Count the number of detected objects\n","    total_value = sum(coin_value_mapping[coin_type] * count for coin_type, count in coin_counts.items())\n","\n","    font_size = 1.1\n","    font_thickness = 2\n","    # Specify the font explicitly\n","    font = cv2.FONT_HERSHEY_SIMPLEX\n","    cv2.putText(frame, f'Number of Objects: {counter}', (10, 50), font, font_size, (255, 0, 0), font_thickness, cv2.LINE_AA)\n","    cv2.putText(frame, f'Total Value: {total_value:.2f} JD', (10, 20), font, font_size, (255, 0, 0), font_thickness, cv2.LINE_AA)\n","\n","    # Write the frame to the output video\n","    out.write(frame)\n","\n","cap.release()\n","out.release()\n","cv2.destroyAllWindows()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
